# 🔥 高频面试题汇总

## 🎯 基础架构类

### Transformer核心
1. **Q**: 解释Transformer中的自注意力机制
   **A**: 自注意力机制通过计算序列中每个位置与其他位置的关联权重，使模型能够捕获长距离依赖关系。核心公式：
   $$
   \text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
   $$

2. **Q**: 为什么使用多头注意力而不是单头？
   **A**: 多头注意力允许模型同时关注不同子空间的信息，每个头可以学习不同类型的关系，提高模型表达能力。

3. **Q**: 位置编码的作用是什么？有哪些类型？
   **A**: 为模型提供序列位置信息，因为注意力机制本身不包含位置概念。包括绝对位置编码（可学习、Sinusoidal）和相对位置编码（RoPE、ALiBi）。

### 模型架构类
4. **Q**: LLaMA和GPT架构的主要区别？
   **A**: 主要区别在于：
   - LLaMA使用RMSNorm和SwiGLU激活函数
   - LLaMA使用RoPE位置编码
   - LLaMA开源，GPT闭源

5. **Q**: Encoder-Only、Decoder-Only、Encoder-Decoder架构分别适合什么任务？
   **A**: 
   - Encoder-Only：理解任务（分类、NER）
   - Decoder-Only：生成任务（文本生成、对话）
   - Encoder-Decoder：序列到序列任务（翻译、摘要）

## ⚙️ 训练优化类

6. **Q**: 解释LoRA微调的原理和优势
   **A**: LoRA通过低秩分解模拟全量微调，将权重更新表示为低秩矩阵乘积：ΔW = BA。优势：
   - 减少可训练参数（1-10%）
   - 保持模型质量
   - 易于部署和切换

7. **Q**: ZeRO-1、ZeRO-2、ZeRO-3的区别？
   **A**: 
   - ZeRO-1：优化器状态分片
   - ZeRO-2：优化器状态+梯度分片
   - ZeRO-3：优化器状态+梯度+参数分片

8. **Q**: FlashAttention如何优化内存使用？
   **A**: FlashAttention通过IO感知的算法设计，减少HBM访问次数，将内存复杂度从O(N²)降低到O(N)，同时保持精确注意力。

## 🚀 推理部署类

9. **Q**: 如何估算大模型的显存需求？
   **A**: 显存需求包括：
   - 模型参数：参数量 × 精度字节数
   - 激活值：取决于batch size和序列长度
   - 优化器状态：参数量的2-4倍
   - KV缓存：序列长度 × 层数 × 隐藏维度

10. **Q**: 模型量化的原理和常见方法？
    **A**: 量化将浮点权重转换为低精度整数，常见方法：
    - 权重量化：INT8、INT4
    - 激活量化：动态量化
    - 量化感知训练：QAT

## 📊 实战计算题

### 计算题1：显存估算
**题目**：一个7B参数的FP16模型，batch_size=4，seq_len=2048，估算推理显存需求？

**解答**：
- 模型参数：7B × 2字节 = 14GB
- KV缓存：2048 × 32层 × 4096维度 × 2 × 4 = 2GB
- 激活值：约1-2GB
- **总计**：约17-18GB

### 计算题2：训练时间估算
**题目**：使用1000张A100训练175B模型，数据量300B tokens，估算训练时间？

**解答**：
- 单卡算力：312 TFLOPS
- 有效算力：约30%利用率
- 计算量：6 × 175B × 300B = 3.15×10²³ FLOPs
- **训练时间**：约3-4个月

## 🎯 开放性问题

11. **Q**: 如何解决大模型的幻觉问题？
    **A**: 多种策略结合：
    - 数据质量提升
    - RLHF对齐训练
    - 知识增强（RAG）
    - 事实核查机制

12. **Q**: 如何评估大模型的安全性？
    **A**: 多维度评估：
    - 有害内容检测
    - 偏见测试
    - 鲁棒性测试
    - 隐私泄露测试

13. **Q**: 大模型在垂直领域如何落地？
    **A**: 完整流程：
    - 领域数据收集
    - 继续预训练
    - 指令微调
    - 强化学习对齐
    - 评估和优化

## 📚 面试技巧

### 回答框架
1. **定义**：清晰解释概念
2. **原理**：说明工作机制
3. **优缺点**：客观分析
4. **应用**：结合实际场景
5. **扩展**：相关技术发展

### 注意事项
- 用具体数字支撑观点
- 结合实际项目经验
- 展示系统性思考
- 承认知识边界

## 🔗 相关资源
- [基础架构详解](../transformer/README.md)
- [训练优化技巧](../pretrain/README.md)
- [模型架构对比](../models/README.md)