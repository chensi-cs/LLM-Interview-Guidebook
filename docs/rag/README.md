# ğŸ“š RAGæŠ€æœ¯

## ğŸ¯ æ¦‚è¿°
RAG (Retrieval-Augmented Generation) é€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†å¢å¼ºå¤§æ¨¡å‹èƒ½åŠ›ï¼Œè§£å†³çŸ¥è¯†æ—¶æ•ˆæ€§å’Œå¹»è§‰é—®é¢˜ã€‚

## ğŸ—ï¸ RAGæ¶æ„

### 1ï¸âƒ£ åŸºç¡€RAGæµç¨‹
```mermaid
graph TD
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[æ£€ç´¢å™¨]
    B --> C[çŸ¥è¯†åº“]
    C --> D[ç›¸å…³æ–‡æ¡£]
    D --> E[ç”Ÿæˆå™¨]
    E --> F[å¢å¼ºå›ç­”]
```

### 2ï¸âƒ£ æ ¸å¿ƒç»„ä»¶
- **æ£€ç´¢å™¨**ï¼šDense Passage Retrievalã€ColBERT
- **ç”Ÿæˆå™¨**ï¼šå¤§è¯­è¨€æ¨¡å‹
- **çŸ¥è¯†åº“**ï¼šå‘é‡æ•°æ®åº“ã€æ–‡æ¡£å­˜å‚¨

## ğŸ—ï¸ æ£€ç´¢æŠ€æœ¯

### 1ï¸âƒ£ å¯†é›†æ£€ç´¢
- **DPR**ï¼šåŒç¼–ç å™¨æ¶æ„
- **Contriever**ï¼šæ— ç›‘ç£é¢„è®­ç»ƒ
- **ColBERT**ï¼šå»¶è¿Ÿäº¤äº’æ¨¡å‹

### 2ï¸âƒ£ æ··åˆæ£€ç´¢
- **ç¨ å¯†+ç¨€ç–**ï¼šç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢
- **é‡æ’åº**ï¼šäº¤å‰ç¼–ç å™¨ç²¾æ’
- **å¤šè·¯å¬å›**ï¼šæé«˜å¬å›ç‡

## ğŸ“Š å‘é‡æ•°æ®åº“å¯¹æ¯”
| æ•°æ®åº“ | ç‰¹ç‚¹ | æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|---|---|---|---|
| **FAISS** | é«˜æ•ˆç›¸ä¼¼åº¦æœç´¢ | é«˜ | ç ”ç©¶åŸå‹ |
| **Pinecone** | æ‰˜ç®¡æœåŠ¡ | é«˜ | ç”Ÿäº§ç¯å¢ƒ |
| **Weaviate** | å›¾æ•°æ®åº“ | ä¸­ | å¤æ‚å…³ç³» |
| **Milvus** | åˆ†å¸ƒå¼ | é«˜ | å¤§è§„æ¨¡æ•°æ® |

## ğŸ¯ å®æˆ˜ä»£ç 
```python
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åˆå§‹åŒ–ç»„ä»¶
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

# æ„å»ºçŸ¥è¯†åº“
documents = text_splitter.split_documents(raw_documents)
vectorstore = FAISS.from_documents(documents, embeddings)

# æ£€ç´¢å¢å¼º
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever
)
```

## ğŸ¯ é¢è¯•é‡ç‚¹
1. **RAGå¦‚ä½•è§£å†³å¹»è§‰é—®é¢˜ï¼Ÿ**
2. **ç¨ å¯†æ£€ç´¢vsç¨€ç–æ£€ç´¢çš„åŒºåˆ«ï¼Ÿ**
3. **å¦‚ä½•è¯„ä¼°RAGç³»ç»Ÿçš„æ•ˆæœï¼Ÿ**
4. **RAGçš„å±€é™æ€§å’Œæ”¹è¿›æ–¹å‘ï¼Ÿ**